{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 748/748 [00:00<00:00, 180kB/s]\n",
      "Downloading: 100%|██████████| 3.92k/3.92k [00:00<00:00, 1.21MB/s]\n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 566B/s]\n",
      "Downloading: 100%|██████████| 674/674 [00:00<00:00, 467kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 26.0kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 897kB/s] \n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 54.2kB/s]\n",
      "Downloading: 100%|██████████| 1.42G/1.42G [00:25<00:00, 56.3MB/s]\n",
      "Downloading: 100%|██████████| 52.0/52.0 [00:00<00:00, 6.84kB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 104kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.91MB/s]\n",
      "Downloading: 100%|██████████| 1.17k/1.17k [00:00<00:00, 182kB/s]\n",
      "Downloading: 100%|██████████| 798k/798k [00:00<00:00, 1.36MB/s]\n",
      "Downloading: 100%|██████████| 191/191 [00:00<00:00, 28.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "# List of models optimized for semantic textual similarity can be found at:\n",
    "# https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/edit#gid=0\n",
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Sentence 1: After an impressive soccer game, the home team was unable to qualify.\n",
      "Sentence 2: Soccer\n",
      "Similarity score: 0.347704142332077\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"After an impressive game, the home team was unable to qualify.\"\n",
    "sentence2 = \"Soccer\"\n",
    "\n",
    "# encode sentences to get their embeddings\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "print(\"Sentence 1:\", sentence1)\n",
    "print(\"Sentence 2:\", sentence2)\n",
    "print(\"Similarity score:\", cosine_scores.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.8188023567199707\n",
      "\n",
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: -0.06005367636680603\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.12721936404705048\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.4131842255592346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"I like Python because I can build AI applications\", \"The cat sits on the ground\"]   \n",
    "sentences2 = [\"I like Python because I can do data analytics\", \"The cat walks on the sidewalk\"]\n",
    "\n",
    "# encode list of sentences to get their embeddings\n",
    "embedding1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    for j in range(len(sentences2)):\n",
    "        print(\"Sentence 1:\", sentences1[i])\n",
    "        print(\"Sentence 2:\", sentences2[j])\n",
    "        print(\"Similarity Score:\", cosine_scores[i][j].item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Top K most similar sentences from a corpus given a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I like Python because I can build AI applications\",\n",
    "          \"I like Python because I can do data analytics\",\n",
    "          \"The cat sits on the ground\",\n",
    "         \"The cat walks on the sidewalk\"]\n",
    "\n",
    "# encode corpus to get corpus embeddings\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I like Javascript because I can build web applications\"\n",
    "\n",
    "# encode sentence to get sentence embeddings\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I like Javascript because I can build web applications \n",
      "\n",
      "Top 2 most similar sentences in corpus:\n",
      "I like Python because I can build AI applications (Score: 0.6253)\n",
      "I like Python because I can do data analytics (Score: 0.5348)\n"
     ]
    }
   ],
   "source": [
    "# top_k results to return\n",
    "top_k=2\n",
    "\n",
    "# compute similarity scores of the sentence with the corpus\n",
    "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
    "\n",
    "# Sort the results in decreasing order and get the first top_k\n",
    "top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "print(\"Sentence:\", sentence, \"\\n\")\n",
    "print(\"Top\", top_k, \"most similar sentences in corpus:\")\n",
    "for idx in top_results[0:top_k]:\n",
    "    print(corpus[idx], \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 391/391 [00:00<00:00, 205kB/s]\n",
      "Downloading: 100%|██████████| 3.95k/3.95k [00:00<00:00, 809kB/s]\n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 451B/s]\n",
      "Downloading: 100%|██████████| 625/625 [00:00<00:00, 102kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 20.2kB/s]\n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 54.1kB/s]\n",
      "Downloading: 100%|██████████| 438M/438M [00:08<00:00, 54.0MB/s] \n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 7.01kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 15.3kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:00<00:00, 741kB/s]  \n",
      "Downloading: 100%|██████████| 399/399 [00:00<00:00, 100kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 661kB/s] \n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 41.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"After an impressive game, the home team was unable to qualify.\"\n",
    "sentence2 = \"Soccer\"\n",
    "\n",
    "sentences = [sentence1, sentence2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18241435]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 399/399 [00:00<00:00, 368kB/s]\n",
      "Downloading: 100%|██████████| 625/625 [00:00<00:00, 176kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 482kB/s]  \n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 810kB/s]  \n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 343B/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 18.4kB/s]\n",
      "Downloading: 100%|██████████| 418M/418M [00:06<00:00, 64.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"After an impressive game, the home team was unable to qualify.\"\n",
    "sentence2 = \"Soccer\"\n",
    "\n",
    "sentences = [sentence1, sentence2]\n",
    "\n",
    "# initialize dictionary to store tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # encode each sentence and append to dictionary\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1639,  0.0275,  1.2470,  ..., -0.2369, -0.1089,  0.2385],\n",
       "         [-0.1594, -0.1702,  1.2940,  ..., -0.3311, -0.3406, -0.2195],\n",
       "         [-0.2658, -0.3155,  1.0049,  ..., -0.0704, -0.3765,  0.1148],\n",
       "         ...,\n",
       "         [-0.3088,  0.0668,  0.6455,  ..., -0.0346, -0.2720, -0.1935],\n",
       "         [-0.4527,  0.0374,  0.7982,  ..., -0.0596, -0.4605, -0.0555],\n",
       "         [-0.4068, -0.0271,  0.8607,  ...,  0.0413, -0.4610, -0.0447]],\n",
       "\n",
       "        [[-0.1715, -0.3728,  1.0104,  ...,  0.7672,  0.1038,  0.6650],\n",
       "         [ 0.0963, -0.2661,  0.7266,  ...,  0.3612, -0.2968,  0.5426],\n",
       "         [ 0.2132, -0.2210,  1.4766,  ...,  1.0731, -0.2669,  0.4364],\n",
       "         ...,\n",
       "         [-0.2084, -0.8132,  0.9243,  ...,  0.7807,  0.0150,  0.5773],\n",
       "         [-0.2169, -0.7170,  0.9179,  ...,  0.6110, -0.0121,  0.7616],\n",
       "         [-0.1951, -0.7552,  0.9375,  ...,  0.6177, -0.0341,  0.7321]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18241435]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "# calculate\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
